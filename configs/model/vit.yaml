_target_: src.models.training_module.TrainingLitModule

optimizer:
  _target_: torch.optim.AdamW
  _partial_: true
  lr: 0.001
  weight_decay: 0.0

scheduler:
  _target_: torch.optim.lr_scheduler.MultiStepLR
  _partial_: true
  milestones: [100, 150]
  gamma: 0.1

net:
  _target_: src.models.components.vit_rollout_multihead.VitRolloutMultihead
  model_name: "vit_tiny_patch16_224.augreg_in21k"
  pretrained: True
  weight_path: null
  output_size: 1
  return_nodes: "attn_drop"
  head_name: "head"
  discard_ratio: 0.2
  head_fusion: "mean"
  visualize: False

# compile model for faster training with pytorch 2.0
compile: false
