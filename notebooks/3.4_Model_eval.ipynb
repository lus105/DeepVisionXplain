{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "from tqdm.notebook import tqdm\n",
    "import rootutils\n",
    "import torchvision.transforms as T\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "rootutils.setup_root(\n",
    "    os.path.abspath(''), indicator=['.git', 'pyproject.toml'], pythonpath=True\n",
    ")\n",
    "\n",
    "from helpers.inference.inference_onnx import InferenceOnnx\n",
    "from helpers.inference.inference_trt import InferenceTensorRT\n",
    "\n",
    "from src.data.components.preprocessing.preproc_pipeline_manager import (\n",
    "    PreprocessingPipeline,\n",
    ")\n",
    "from src.data.components.preprocessing.preproc_strategy_split import SplitStep\n",
    "from src.data.components.preprocessing.preproc_strategy_tile import TilingStep\n",
    "from src.data.classification_datamodule import ClassificationDataModule\n",
    "\n",
    "# loading .env variables\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_test_transforms = T.Compose(\n",
    "    [\n",
    "        T.ToTensor(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "split_step = SplitStep(\n",
    "    split_ratio=[0.7, 0.2, 0.1],\n",
    "    seed=42,\n",
    "    merge_classes=True,\n",
    ")\n",
    "\n",
    "tiling_step = TilingStep(\n",
    "    tile_size=[224, 224],\n",
    "    min_defective_area_th=0.1,\n",
    "    discard_background_th=0.0,\n",
    "    overlap=10,\n",
    "    contour_iter_step_size=10,\n",
    "    iterate_over_defective_areas=True,\n",
    ")\n",
    "\n",
    "preprocessing_pipeline = PreprocessingPipeline([split_step, tiling_step])\n",
    "\n",
    "# Initialize the DataModule\n",
    "data_dir = os.environ.get('seats_data_path')\n",
    "data_module = ClassificationDataModule(\n",
    "    data_dir=data_dir,\n",
    "    preprocessing_pipeline=preprocessing_pipeline,\n",
    "    batch_size=1,\n",
    "    num_workers=3,\n",
    "    pin_memory=False,\n",
    "    val_test_transforms=val_test_transforms,\n",
    ")\n",
    "\n",
    "# Set up the test dataset\n",
    "data_module.prepare_data()\n",
    "data_module.setup(stage='test')\n",
    "test_loader = data_module.test_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model):\n",
    "    results = []\n",
    "    for batch in tqdm(test_loader, desc='Evaluating'):\n",
    "        inputs, labels = batch\n",
    "\n",
    "        if isinstance(model, torch.nn.Module):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            predictions = (outputs[0] > 0.5).int().cpu().numpy()\n",
    "            labels = labels.cpu().numpy()\n",
    "\n",
    "        elif isinstance(model, InferenceOnnx) or isinstance(model, InferenceTensorRT):\n",
    "            inputs = inputs.numpy()\n",
    "            labels = labels.numpy()\n",
    "            outputs = model(inputs)\n",
    "            predictions = (outputs[0] > 0.5).astype(int)\n",
    "\n",
    "        results.append((predictions, labels))\n",
    "\n",
    "    # Metrics calculation\n",
    "    all_preds, all_labels = zip(*results)\n",
    "    all_preds = np.concatenate(all_preds)\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    print(f'Accuracy: {accuracy * 100:.2f}%')\n",
    "    print(classification_report(all_labels, all_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_onnx = InferenceOnnx('efficientnet_v2_s_downscaled_pcb.onnx')\n",
    "evaluate(inference_onnx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_trt = InferenceTensorRT('efficientnet_v2_s_downscaled_pcb_fp32.trt')\n",
    "evaluate(inference_trt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.components.cnn_cam_multihead import CNNCAMMultihead\n",
    "from src.models.components.nn_utils import weight_load\n",
    "\n",
    "model = CNNCAMMultihead(\n",
    "    backbone='torchvision.models/efficientnet_v2_s',\n",
    "    return_node='features.6.0.block.0',\n",
    "    multi_head=True,\n",
    ").to(device)\n",
    "weights = weight_load(\n",
    "    ckpt_path='../trained_models/models--DeepVisionXplain--efficientnet_v2_s_downscaled_pcb/',\n",
    "    weights_only=True,\n",
    ")\n",
    "model.load_state_dict(weights)\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    evaluate(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepVisionXplain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
