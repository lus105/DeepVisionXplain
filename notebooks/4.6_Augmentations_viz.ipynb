{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import rootutils\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "from IPython.display import display\n",
    "\n",
    "import torchvision.transforms as T\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "rootutils.setup_root(\n",
    "    os.path.abspath(''), indicator=['.git', 'pyproject.toml'], pythonpath=True\n",
    ")\n",
    "\n",
    "from src.data.components.utils import list_files, find_file_by_name\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_path = Path(os.environ.get('lear_outline_data_path'))\n",
    "image_path = source_path / 'train' / 'images'\n",
    "mask_path = source_path / 'train' / 'labels'\n",
    "image_paths = list_files(image_path, file_extensions=['.bmp', '.jpg', '.png'])\n",
    "image = cv2.imread(str(image_paths[0]), cv2.IMREAD_COLOR)\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "mask = cv2.imread(str(find_file_by_name(mask_path, image_paths[0].stem)), cv2.IMREAD_GRAYSCALE)\n",
    "image_to_pil = T.ToPILImage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Horizontal flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = A.Compose([\n",
    "    A.Resize(\n",
    "        height = 768,\n",
    "        width = 640\n",
    "        ),\n",
    "    A.HorizontalFlip(p=1),\n",
    "    A.ToFloat(max_value=255),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "transformed = transform(image=image, mask=mask)\n",
    "image_tensor = transformed['image']\n",
    "mask_tensor = transformed['mask']\n",
    "display(image_to_pil(image_tensor))\n",
    "display(image_to_pil(mask_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = A.Compose([\n",
    "    A.Resize(\n",
    "        height = 768,\n",
    "        width = 640\n",
    "        ),\n",
    "    A.ShiftScaleRotate(p=1, rotate_limit = [-5, 5], scale_limit = [-0.03, 0.03], shift_limit = [-0.02, 0.02]),\n",
    "    A.ToFloat(max_value=255),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "transformed = transform(image=image, mask=mask)\n",
    "image_tensor = transformed['image']\n",
    "mask_tensor = transformed['mask']\n",
    "display(image_to_pil(image_tensor))\n",
    "display(image_to_pil(mask_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = A.Compose([\n",
    "    A.Resize(\n",
    "        height = 768,\n",
    "        width = 640\n",
    "        ),\n",
    "    A.RandomBrightnessContrast(p=1, brightness_limit=0.1, contrast_limit=0.1),\n",
    "    A.ToFloat(max_value=255),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "transformed = transform(image=image, mask=mask)\n",
    "image_tensor = transformed['image']\n",
    "mask_tensor = transformed['mask']\n",
    "display(image_to_pil(image_tensor))\n",
    "display(image_to_pil(mask_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = A.Compose([\n",
    "    A.Resize(\n",
    "        height = 768,\n",
    "        width = 640\n",
    "        ),\n",
    "    A.RandomGamma(p=1, gamma_limit=[30, 150]),\n",
    "    A.ToFloat(max_value=255),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "transformed = transform(image=image, mask=mask)\n",
    "image_tensor = transformed['image']\n",
    "mask_tensor = transformed['mask']\n",
    "display(image_to_pil(image_tensor))\n",
    "display(image_to_pil(mask_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = A.Compose([\n",
    "    A.Resize(\n",
    "        height = 768,\n",
    "        width = 640\n",
    "        ),\n",
    "    A.GaussNoise(p=1, std_range=[0.01, 0.10]),\n",
    "    A.ToFloat(max_value=255),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "transformed = transform(image=image, mask=mask)\n",
    "image_tensor = transformed['image']\n",
    "mask_tensor = transformed['mask']\n",
    "display(image_to_pil(image_tensor))\n",
    "display(image_to_pil(mask_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = A.Compose([\n",
    "    A.Resize(\n",
    "        height = 768,\n",
    "        width = 640\n",
    "        ),\n",
    "    A.MotionBlur(p=1, blur_limit=[3, 5]),\n",
    "    A.ToFloat(max_value=255),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "transformed = transform(image=image, mask=mask)\n",
    "image_tensor = transformed['image']\n",
    "mask_tensor = transformed['mask']\n",
    "display(image_to_pil(image_tensor))\n",
    "display(image_to_pil(mask_tensor))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepVisionXplain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
