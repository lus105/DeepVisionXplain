{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from torchsummary import summary\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torchvision.models import efficientnet_b3, efficientnet_v2_s, mobilenet_v3_large\n",
    "from torchvision.models.feature_extraction import (\n",
    "    create_feature_extractor,\n",
    "    get_graph_node_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Model summary \n",
    "# pretrained_model = efficientnet_b3(weights=\"IMAGENET1K_V1\")\n",
    "# pretrained_model = efficientnet_v2_s(weights=\"IMAGENET1K_V1\")\n",
    "pretrained_model = mobilenet_v3_large(weights=\"IMAGENET1K_V1\")\n",
    "\n",
    "model_summary = summary(pretrained_model, (3, 640, 640), depth=5)\n",
    "names = get_graph_node_names(pretrained_model)[1]\n",
    "print(\"Node names (eval):\", names)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extractor\n",
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self, pretrained_model, return_nodes: dict):\n",
    "        super().__init__()\n",
    "        nodes = list(return_nodes.values())\n",
    "        self.out_name = nodes[0]\n",
    "        self.model = create_feature_extractor(pretrained_model, return_nodes=return_nodes)\n",
    "        self.n_features = self._calculate_n_features()\n",
    "\n",
    "    def forward(self, input: torch.Tensor):\n",
    "        features = self.model(input)\n",
    "        return features[self.out_name]\n",
    "\n",
    "    def _calculate_n_features(self):\n",
    "        dummy_input = torch.randn(1, 3, 100, 100)\n",
    "        with torch.no_grad():\n",
    "            output = self.forward(dummy_input)\n",
    "        return output.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output layer consisting of a global average pooling layer and a sigmoid layer\n",
    "class OutputLayer(nn.Module):\n",
    "    def __init__(self, last_layer_features: int):\n",
    "        super().__init__()\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.sigmoid_fc = nn.Linear(last_layer_features, 1)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = self.global_avg_pool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.sigmoid_fc(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cam generator\n",
    "class CAMGenerator(nn.Module):\n",
    "    def __init__(self, sigmoid_fc: torch.nn.modules.linear.Linear):\n",
    "        super().__init__()\n",
    "        self.sigmoid_fc = sigmoid_fc\n",
    "\n",
    "    def forward(self, input: torch.Tensor, features: torch.Tensor):\n",
    "        weights = self.sigmoid_fc.weight.data.unsqueeze(-1).unsqueeze(-1)\n",
    "        cam = torch.einsum(\"ijkl,ijkl->ikl\", features, weights).unsqueeze(1)  # (B, 1, H, W)\n",
    "        cam = F.interpolate(\n",
    "            cam, size=input.size()[2:], mode=\"bilinear\", align_corners=False\n",
    "        ).squeeze(\n",
    "            1\n",
    "        )  # (B, H, W)\n",
    "        return cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-Head model \n",
    "# Note that return_nodes are hardcoded        \n",
    "\n",
    "class MultiHeadBase(nn.Module):\n",
    "    def __init__(self, backbone, return_node, weights, generate_cam):\n",
    "        super().__init__()\n",
    "        pretrained_model = backbone(weights=weights)\n",
    "        self.feature_extractor = FeatureExtractor(pretrained_model, return_node)\n",
    "        self.output_layer = OutputLayer(self.feature_extractor.n_features)\n",
    "        self.cam_generator = CAMGenerator(self.output_layer.sigmoid_fc)\n",
    "        self.generate_cam = generate_cam\n",
    "\n",
    "    def forward(self, input):\n",
    "        features = self.feature_extractor(input)\n",
    "        sigmoid_output = self.output_layer(features)\n",
    "        if self.generate_cam:\n",
    "            cam = self.cam_generator(input, features)\n",
    "            return sigmoid_output, cam\n",
    "        else:\n",
    "            return sigmoid_output, None\n",
    "\n",
    "class EfficientNetB3(MultiHeadBase):\n",
    "    def __init__(self, weights=\"IMAGENET1K_V1\", generate_cam=False):\n",
    "        return_nodes = {'features.5.1.block.2': 'layerout'}\n",
    "        super().__init__(efficientnet_b3, return_nodes, weights, generate_cam) \n",
    "\n",
    "class EfficientNetV2S(MultiHeadBase):\n",
    "    def __init__(self, weights=\"IMAGENET1K_V1\", generate_cam=False):\n",
    "        return_nodes = {'features.6.11.block.0': 'layerout'}\n",
    "        super().__init__(efficientnet_v2_s, return_nodes, weights, generate_cam)  \n",
    "        \n",
    "class MobileNetV3Large(MultiHeadBase):  \n",
    "     def __init__(self, weights=\"IMAGENET1K_V1\", generate_cam=False):\n",
    "        return_nodes = {'features.16': 'layerout'}\n",
    "        super().__init__(mobilenet_v3_large, return_nodes, weights, generate_cam)  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    EfficientNetB3(generate_cam=True), \n",
    "    EfficientNetV2S(generate_cam=True), \n",
    "    MobileNetV3Large(generate_cam=True)\n",
    "]\n",
    "\n",
    "for model in models:\n",
    "    \n",
    "    # Check if the model and CAM module outputs reasonable shapes\n",
    "    model.eval()\n",
    "    # Assume batch size of 10\n",
    "    dummy_input = torch.randn(10, 3, 640, 640)\n",
    "    with torch.no_grad():\n",
    "        out, cam = model(dummy_input)\n",
    "    \n",
    "    print(model.__class__.__name__)\n",
    "    print(\"Output shape:\", out.shape)\n",
    "    print(\"CAM shape:\", cam.shape)\n",
    "    print(\"\\n\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepVisionXplain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
