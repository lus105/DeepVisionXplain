{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running inference:\n",
    "1. Run [3.2_Model_conversion_trt.ipynb](3.2_Model_conversion_trt.ipynb) to convert models .onnx files into .trt\n",
    "2. Make sure TensorRT [binaries](https://developer.nvidia.com/tensorrt/download/10x) are present and added to [Path](https://medium.com/@guillermovc/how-to-install-tensorrt-in-windows-10-71a4033c4407).\n",
    "3. Make sure pycuda and tensorrt is installed via pip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "from IPython.display import display\n",
    "import tensorrt as trt\n",
    "import cv2\n",
    "\n",
    "from helpers.processing import display_img_with_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/59280745/inference-with-tensorrt-engine-file-on-python\n",
    "class TensorRTInference:\n",
    "    def __init__(self, engine_path):\n",
    "        # initialize\n",
    "        self.logger = trt.Logger(trt.Logger.ERROR)\n",
    "        self.runtime = trt.Runtime(self.logger)\n",
    "\n",
    "        # setup\n",
    "        self.engine = self.load_engine(engine_path)\n",
    "        self.context = self.engine.create_execution_context()\n",
    "\n",
    "        # allocate buffers\n",
    "        self.inputs, self.outputs, self.bindings, self.stream = self.allocate_buffers(\n",
    "            self.engine\n",
    "        )\n",
    "\n",
    "    def load_engine(self, engine_path):\n",
    "        # loads the model from given filepath\n",
    "        with open(engine_path, \"rb\") as f:\n",
    "            engine = self.runtime.deserialize_cuda_engine(f.read())\n",
    "        return engine\n",
    "\n",
    "    class HostDeviceMem:\n",
    "        def __init__(self, host_mem, device_mem, shape):\n",
    "            # keeping track of addresses\n",
    "            self.host = host_mem\n",
    "            self.device = device_mem\n",
    "            # keeping track of shape to un-flatten it later\n",
    "            self.shape = shape\n",
    "\n",
    "    def allocate_buffers(self, engine):\n",
    "        inputs, outputs, bindings = [], [], []\n",
    "        stream = cuda.Stream()\n",
    "\n",
    "        for i in range(engine.num_io_tensors):\n",
    "            tensor_name = engine.get_tensor_name(i)\n",
    "            shape = engine.get_tensor_shape(tensor_name)\n",
    "            size = trt.volume(shape)\n",
    "            dtype = trt.nptype(engine.get_tensor_dtype(tensor_name))\n",
    "\n",
    "            # allocate host and device buffers\n",
    "            host_mem = cuda.pagelocked_empty(size, dtype)\n",
    "            device_mem = cuda.mem_alloc(host_mem.nbytes)\n",
    "\n",
    "            # append the device buffer address to device bindings\n",
    "            bindings.append(int(device_mem))\n",
    "\n",
    "            # append to the appropiate input/output list\n",
    "            if engine.get_tensor_mode(tensor_name) == trt.TensorIOMode.INPUT:\n",
    "                inputs.append(self.HostDeviceMem(host_mem, device_mem, shape))\n",
    "            else:\n",
    "                outputs.append(self.HostDeviceMem(host_mem, device_mem, shape))\n",
    "\n",
    "        return inputs, outputs, bindings, stream\n",
    "\n",
    "    def infer(self, input_data):\n",
    "        # transfer input data to device\n",
    "        np.copyto(self.inputs[0].host, input_data.ravel())\n",
    "        cuda.memcpy_htod_async(self.inputs[0].device, self.inputs[0].host, self.stream)\n",
    "\n",
    "        # set tensor address\n",
    "        for i in range(self.engine.num_io_tensors):\n",
    "            self.context.set_tensor_address(\n",
    "                self.engine.get_tensor_name(i), self.bindings[i]\n",
    "            )\n",
    "\n",
    "        # run inference\n",
    "        self.context.execute_async_v3(stream_handle=self.stream.handle)\n",
    "\n",
    "        # transfer predictions back\n",
    "        for i in range(len(self.outputs)):\n",
    "            cuda.memcpy_dtoh_async(\n",
    "                self.outputs[i].host, self.outputs[i].device, self.stream\n",
    "            )\n",
    "\n",
    "        # synchronize the stream\n",
    "        self.stream.synchronize()\n",
    "\n",
    "        # un-flatten the outputs\n",
    "        outputs = []\n",
    "        for i in range(len(self.outputs)):\n",
    "            output = self.outputs[i].host\n",
    "            output = output.reshape(self.outputs[i].shape)\n",
    "            outputs.append(output)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine_path = 'efficientnet_v2_s_downscaled_pcb_fp32.trt'\n",
    "trt_inference = TensorRTInference(engine_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('../docs/sample_data/01_short_04_1926_1070.png', cv2.IMREAD_COLOR)\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "tensor = transform(image).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "trt_inference.infer(tensor.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = trt_inference.infer(tensor.numpy())\n",
    "display_img_with_map(outputs[0], outputs[1], image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine_path = 'efficientnet_v2_s_downscaled_pcb_fp16.trt'\n",
    "trt_inference = TensorRTInference(engine_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "trt_inference.infer(tensor.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = trt_inference.infer(tensor.numpy())\n",
    "display_img_with_map(outputs[0], outputs[1], image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine_path = 'vit_tiny_patch16_224.augreg_in21k_ft_in1k_pcb_fp32.trt'\n",
    "trt_inference = TensorRTInference(engine_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "trt_inference.infer(tensor.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = trt_inference.infer(tensor.numpy())\n",
    "display_img_with_map(outputs[0], outputs[1], image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine_path = 'vit_tiny_patch16_224.augreg_in21k_ft_in1k_pcb_fp16.trt'\n",
    "trt_inference = TensorRTInference(engine_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "trt_inference.infer(tensor.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = trt_inference.infer(tensor.numpy())\n",
    "display_img_with_map(outputs[0], outputs[1], image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepVisionXplain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
