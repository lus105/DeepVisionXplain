{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import rootutils\n",
    "import torch\n",
    "\n",
    "# adding root to python path\n",
    "rootutils.setup_root(\n",
    "    os.path.abspath(''), indicator=['.git', 'pyproject.toml'], pythonpath=True\n",
    ")\n",
    "\n",
    "from src.models.components.cnn_cam_multihead import CNNCAMMultihead\n",
    "from src.models.components.vit_rollout_multihead import VitRolloutMultihead\n",
    "from src.models.components.nn_utils import weight_load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = CNNCAMMultihead(\n",
    "    backbone='torchvision.models/efficientnet_v2_s',\n",
    "    return_node='features.6.0.block.0',\n",
    "    multi_head=True,\n",
    ")\n",
    "weights = weight_load(\n",
    "    ckpt_path='../trained_models/models--DeepVisionXplain--efficientnet_v2_s_downscaled_pcb/',\n",
    "    weights_only=True,\n",
    ")\n",
    "cnn_model.load_state_dict(weights)\n",
    "cnn_model.eval()\n",
    "x = torch.randn((1, 3, 224, 224))\n",
    "torch.onnx.export(\n",
    "    cnn_model,\n",
    "    x,\n",
    "    'efficientnet_v2_s_downscaled_pcb.onnx',\n",
    "    export_params=True,\n",
    "    opset_version=12,\n",
    "    do_constant_folding=True,\n",
    "    input_names=['input'],\n",
    "    output_names=['map', 'output'],\n",
    "    dynamic_axes={\n",
    "        'input': {0: 'batch_size'},\n",
    "        'map': {0: 'batch_size'},\n",
    "        'output': {0: 'batch_size'},\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ViT export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vit_model = VitRolloutMultihead(\n",
    "    backbone='timm/vit_tiny_patch16_224.augreg_in21k_ft_in1k', multi_head=True\n",
    ")\n",
    "weights = weight_load(\n",
    "    ckpt_path='../trained_models/models--DeepVisionXplain--vit_tiny_patch16_224.augreg_in21k_ft_in1k_pcb/',\n",
    "    weights_only=True,\n",
    ")\n",
    "vit_model.load_state_dict(weights)\n",
    "vit_model.eval()\n",
    "x = torch.randn((1, 3, 224, 224))\n",
    "torch.onnx.export(\n",
    "    vit_model,\n",
    "    x,\n",
    "    'vit_tiny_patch16_224.augreg_in21k_ft_in1k_pcb.onnx',\n",
    "    export_params=True,\n",
    "    opset_version=12,\n",
    "    do_constant_folding=True,\n",
    "    input_names=['input'],\n",
    "    output_names=['map', 'output'],\n",
    "    dynamic_axes={\n",
    "        'input': {0: 'batch_size'},\n",
    "        'map': {0: 'batch_size'},\n",
    "        'output': {0: 'batch_size'},\n",
    "    },\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepVisionXplain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
