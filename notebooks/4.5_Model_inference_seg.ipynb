{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import rootutils\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "from IPython.display import display\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# adding root to python path\n",
    "rootutils.setup_root(\n",
    "    os.path.abspath(''), indicator=['.git', 'pyproject.toml'], pythonpath=True\n",
    ")\n",
    "\n",
    "from src.models.components.base_model import BaseModel\n",
    "from src.models.components.nn_utils import weight_load\n",
    "from src.data.components.utils import list_files\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read seat image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_path = Path(os.environ.get('lear_wrinkles_data_path'))\n",
    "image_paths = list_files(source_path, file_extensions=['.bmp', '.jpg', '.png'])\n",
    "image = cv2.imread(str(image_paths[0]), cv2.IMREAD_COLOR)\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = A.Compose([\n",
    "    A.Resize(\n",
    "        height = 768,\n",
    "        width = 640\n",
    "        ),\n",
    "    A.ToFloat(max_value=255),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "transformed = transform(image=image)\n",
    "image_tensor = transformed['image'].unsqueeze(0).to(device)\n",
    "image_tensor_pil = T.ToPILImage()(image_tensor[0].detach().cpu())\n",
    "display(image_tensor_pil)\n",
    "print('Shape: ', image_tensor.shape, 'Type: ', image_tensor.dtype, 'max: ', image_tensor.max(), 'min: ', image_tensor.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BaseModel(\n",
    "    model_name = 'segmentation_models_pytorch/UnetPlusPlus',\n",
    "    encoder_name = 'mobilenet_v2',\n",
    "    ).to(device)\n",
    "weights = weight_load(\n",
    "    ckpt_path='../trained_models/unet++.ckpt',\n",
    "    weights_only=True,\n",
    ")\n",
    "model.load_state_dict(weights)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "with torch.no_grad():\n",
    "    model(image_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    out = model(image_tensor)\n",
    "\n",
    "mask = torch.sigmoid(out[0])\n",
    "mask = (mask > 0.5).float()\n",
    "mask = T.ToPILImage()(mask.detach().cpu())\n",
    "display(image_tensor_pil)\n",
    "display(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run inference on all samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = source_path / 'masks'\n",
    "output_path.mkdir(exist_ok=True)\n",
    "for path in image_paths:\n",
    "    image = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    transformed = transform(image=image)\n",
    "    image_tensor = transformed['image'].unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        out = model(image_tensor)\n",
    "    out = torch.nn.functional.interpolate(out, size=image.shape[:2], mode=\"bilinear\", align_corners=False)\n",
    "    mask = torch.sigmoid(out[0])\n",
    "    mask = (mask > 0.5).float()\n",
    "\n",
    "    mask = mask.detach().cpu().numpy()\n",
    "    mask = (mask[0] * 255).astype('uint8')\n",
    "    mask_path = output_path / Path(path).name\n",
    "    cv2.imwrite(str(mask_path), mask)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepVisionXplain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
